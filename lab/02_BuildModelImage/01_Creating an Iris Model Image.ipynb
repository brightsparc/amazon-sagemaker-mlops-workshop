{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a R-mars Docker Image\n",
    "We will start our MLOps journey here by creating a Docker Image for training a R-Mars [Multivariate Adaptive Regression Splines](https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines) model.\n",
    "\n",
    "So, after we create and test locally our Dockerfile, we'll send it to our first pipeline that will build this image and make it available in ECR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First create the training code\n",
    "\n",
    "`mars.R` creates functions to fit and serve our model.  The algorithm we've chosen to use is [Multivariate Adaptive Regression Splines](https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines).  This is a suitable example as it's a unique and powerful algorithm, but isn't as broadly used as Amazon SageMaker algorithms, and it isn't available in Python's scikit-learn library.  R's repository of packages is filled with algorithms that share these same criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mars.R\n"
     ]
    }
   ],
   "source": [
    "%%writefile mars.R\n",
    "# Bring in library that contains multivariate adaptive regression splines (MARS)\n",
    "library(mda)\n",
    "\n",
    "# Bring in library that allows parsing of JSON training parameters\n",
    "library(jsonlite)\n",
    "\n",
    "# Bring in library for prediction server\n",
    "library(plumber)\n",
    "\n",
    "\n",
    "# Setup parameters\n",
    "# Container directories\n",
    "prefix <- '/opt/ml'\n",
    "input_path <- paste(prefix, 'input/data', sep='/')\n",
    "output_path <- paste(prefix, 'output', sep='/')\n",
    "model_path <- paste(prefix, 'model', sep='/')\n",
    "param_path <- paste(prefix, 'input/config/hyperparameters.json', sep='/')\n",
    "\n",
    "# Channel holding training data\n",
    "channel_name = 'train'\n",
    "training_path <- paste(input_path, channel_name, sep='/')\n",
    "\n",
    "\n",
    "# Setup training function\n",
    "train <- function() {\n",
    "\n",
    "    # Read in hyperparameters\n",
    "    training_params <- read_json(param_path)\n",
    "\n",
    "    target <- training_params$target\n",
    "\n",
    "    if (!is.null(training_params$degree)) {\n",
    "        degree <- as.numeric(training_params$degree)}\n",
    "    else {\n",
    "        degree <- 2}\n",
    "\n",
    "    # Bring in data\n",
    "    training_files = list.files(path=training_path, full.names=TRUE)\n",
    "    training_data = do.call(rbind, lapply(training_files, read.csv))\n",
    "    \n",
    "    # Convert to model matrix\n",
    "    training_X <- model.matrix(~., training_data[, colnames(training_data) != target])\n",
    "\n",
    "    # Save factor levels for scoring\n",
    "    factor_levels <- lapply(training_data[, sapply(training_data, is.factor), drop=FALSE],\n",
    "                            function(x) {levels(x)})\n",
    "    \n",
    "    # Run multivariate adaptive regression splines algorithm\n",
    "    model <- mars(x=training_X, y=training_data[, target], degree=degree)\n",
    "    \n",
    "    # Generate outputs\n",
    "    mars_model <- model[!(names(model) %in% c('x', 'residuals', 'fitted.values'))]\n",
    "    attributes(mars_model)$class <- 'mars'\n",
    "    save(mars_model, factor_levels, file=paste(model_path, 'mars_model.RData', sep='/'))\n",
    "    print(summary(mars_model))\n",
    "\n",
    "    write.csv(model$fitted.values, paste(output_path, 'data/fitted_values.csv', sep='/'), row.names=FALSE)\n",
    "    write('success', file=paste(output_path, 'success', sep='/'))}\n",
    "\n",
    "\n",
    "# Setup scoring function\n",
    "serve <- function() {\n",
    "    app <- plumb(paste(prefix, 'plumber.R', sep='/'))\n",
    "    app$run(host='0.0.0.0', port=8080)}\n",
    "\n",
    "\n",
    "# Run at start-up\n",
    "args <- commandArgs()\n",
    "if (any(grepl('train', args))) {\n",
    "    train()}\n",
    "if (any(grepl('serve', args))) {\n",
    "    serve()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, create the Serve function\n",
    "\n",
    "`plumber.R` uses the [plumber](https://www.rplumber.io/) package to create a lightweight HTTP server for processing requests in hosting.  Note the specific syntax, and see the plumber help docs for additional detail on more specialized use cases.\n",
    "\n",
    "Per the Amazon SageMaker documentation, our service needs to accept post requests to ping and invocations.  plumber specifies this with custom comments, followed by functions that take specific arguments.\n",
    "\n",
    "Here invocations does most of the work, ingesting our trained model, handling the HTTP request body, and producing a CSV output of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting plumber.R\n"
     ]
    }
   ],
   "source": [
    "%%writefile plumber.R\n",
    "#' Ping to show server is there\n",
    "#' @get /ping\n",
    "function() {\n",
    "    return('')}\n",
    "\n",
    "\n",
    "#' Parse input and return prediction from model\n",
    "#' @param req The http request sent\n",
    "#' @post /invocations\n",
    "function(req) {\n",
    "\n",
    "    # Setup locations\n",
    "    prefix <- '/opt/ml'\n",
    "    model_path <- paste(prefix, 'model', sep='/')\n",
    "\n",
    "    # Bring in model file and factor levels\n",
    "    load(paste(model_path, 'mars_model.RData', sep='/'))\n",
    "        \n",
    "    # Read in data\n",
    "    conn <- textConnection(gsub('\\\\\\\\n', '\\n', req$postBody))\n",
    "    data <- read.csv(conn)\n",
    "    close(conn)\n",
    "\n",
    "    # Convert input to model matrix\n",
    "    scoring_X <- model.matrix(~., data, xlev=factor_levels)\n",
    "\n",
    "    # Return prediction\n",
    "    return(paste(predict(mars_model, scoring_X, row.names=FALSE), collapse=','))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now  create a Dockerfile\n",
    "\n",
    "Create the docker file that references the `mars.R` and `plumbler.R` files we have created.\n",
    "\n",
    "Smaller containers are preferred for Amazon SageMaker as they lead to faster spin up times in training and endpoint creation, so this container is kept minimal.  It simply starts with Ubuntu, installs R, mda, and plumber libraries, then adds `mars.R` and `plumber.R`, and finally runs `mars.R` when the entrypoint is launched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM ubuntu:16.04\n",
    "\n",
    "MAINTAINER Amazon SageMaker Examples <amazon-sagemaker-examples@amazon.com>\n",
    "\n",
    "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\n",
    "    wget \\\n",
    "    r-base \\\n",
    "    r-base-dev \\\n",
    "    ca-certificates\n",
    "\n",
    "RUN R -e \"install.packages(c('mda', 'plumber'), repos='https://cloud.r-project.org')\"\n",
    "\n",
    "COPY mars.R /opt/ml/mars.R\n",
    "COPY plumber.R /opt/ml/plumber.R\n",
    "\n",
    "ENTRYPOINT [\"/usr/bin/Rscript\", \"/opt/ml/mars.R\", \"--no-save\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Finally, let's create the buildspec\n",
    "This file will be used by CodeBuild for creating our base image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting buildspec.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildspec.yml\n",
    "version: 0.2\n",
    "\n",
    "phases:\n",
    "  install:\n",
    "    runtime-versions:\n",
    "      docker: 18\n",
    "\n",
    "  pre_build:\n",
    "    commands:\n",
    "      - echo Logging in to Amazon ECR...\n",
    "      - $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
    "      - docker pull $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/scikit-base:latest\n",
    "      - docker tag $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/scikit-base:latest scikit-base:latest\n",
    "  build:\n",
    "    commands:\n",
    "      - echo Build started on `date`\n",
    "      - echo Building the Docker image...\n",
    "      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
    "      - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "\n",
    "  post_build:\n",
    "    commands:\n",
    "      - echo Build completed on `date`\n",
    "      - echo Pushing the Docker image...\n",
    "      - echo docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - echo $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG > image.url\n",
    "      - echo Done\n",
    "artifacts:\n",
    "  files:\n",
    "    - image.url\n",
    "  name: image_url\n",
    "  discard-paths: yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the image locally, first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  105.5kB\n",
      "Step 1/7 : FROM ubuntu:16.04\n",
      " ---> 5e13f8dd4c1a\n",
      "Step 2/7 : MAINTAINER Amazon SageMaker Examples <amazon-sagemaker-examples@amazon.com>\n",
      " ---> Using cache\n",
      " ---> b92d1fc0d694\n",
      "Step 3/7 : RUN apt-get -y update && apt-get install -y --no-install-recommends     wget     r-base     r-base-dev     ca-certificates\n",
      " ---> Using cache\n",
      " ---> 41f82a5014d8\n",
      "Step 4/7 : RUN R -e \"install.packages(c('mda', 'plumber'), repos='https://cloud.r-project.org')\"\n",
      " ---> Using cache\n",
      " ---> 59c5760cc0dc\n",
      "Step 5/7 : COPY mars.R /opt/ml/mars.R\n",
      " ---> Using cache\n",
      " ---> 911320145c53\n",
      "Step 6/7 : COPY plumber.R /opt/ml/plumber.R\n",
      " ---> ca08c32708f7\n",
      "Step 7/7 : ENTRYPOINT [\"/usr/bin/Rscript\", \"/opt/ml/mars.R\", \"--no-save\"]\n",
      " ---> Running in 2ab53452453b\n",
      "Removing intermediate container 2ab53452453b\n",
      " ---> 12d8a001520d\n",
      "Successfully built 12d8a001520d\n",
      "Successfully tagged sagemaker-rmars:1.0\n"
     ]
    }
   ],
   "source": [
    "!docker build -f Dockerfile -t sagemaker-rmars:1.0 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do some tests, locally\n",
    "## First, let's define some hyperparameters for both algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"degree\": 2,\n",
    "    \"target\": \"Sepal.Length\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "!mkdir -p input/config\n",
    "\n",
    "hyperparameters = dict({key: str(values) for key, values in hyperparameters.items()})\n",
    "with open('input/config/hyperparameters.json', 'w') as f:\n",
    "    f.write(json.dumps(hyperparameters))\n",
    "    f.flush()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, let's prepare a dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sepal.Length,Sepal.Width,Petal.Length,Petal.Width,Species\r\n",
      "5.1,3.5,1.4,0.2,setosa\r\n",
      "4.9,3,1.4,0.2,setosa\r\n",
      "4.7,3.2,1.3,0.2,setosa\r\n",
      "4.6,3.1,1.5,0.2,setosa\r\n",
      "5,3.6,1.4,0.2,setosa\r\n",
      "5.4,3.9,1.7,0.4,setosa\r\n",
      "4.6,3.4,1.4,0.3,setosa\r\n",
      "5,3.4,1.5,0.2,setosa\r\n",
      "4.4,2.9,1.4,0.2,setosa\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p input/data/train\n",
    "!cp iris.csv input/data/train\n",
    "!head input/data/train/iris.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, let's test the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -Rf model\n",
    "!mkdir -p model\n",
    "!rm -Rf output\n",
    "!mkdir -p output/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Loading required package: class\n",
      "Loaded mda 0.4-10\n",
      "\n",
      "Loading required package: methods\n",
      "Warning message:\n",
      "replacing previous import by 'Rcpp::evalCpp' when loading 'later' \n",
      "               Length Class  Mode   \n",
      "call             4    -none- call   \n",
      "all.terms       18    -none- numeric\n",
      "selected.terms   6    -none- numeric\n",
      "penalty          1    -none- numeric\n",
      "degree           1    -none- numeric\n",
      "nk               1    -none- numeric\n",
      "thresh           1    -none- numeric\n",
      "gcv              1    -none- numeric\n",
      "factor         126    -none- numeric\n",
      "cuts           126    -none- numeric\n",
      "lenb             1    -none- numeric\n",
      "coefficients     6    -none- numeric\n"
     ]
    }
   ],
   "source": [
    "print( \"Training ...\")\n",
    "!docker run --rm --name 'my_model' \\\n",
    "    -v \"$PWD/model:/opt/ml/model\" \\\n",
    "    -v \"$PWD/input:/opt/ml/input\" \\\n",
    "    -v \"$PWD/output:/opt/ml/output\" sagemaker-rmars:1.0 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the serving test. It simulates an Endpoint exposed by Sagemaker\n",
    "\n",
    "After you execute the next cell, this Jupyter notebook will freeze. A webservice will be exposed at the port 8080. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading required package: class\n",
      "Loaded mda 0.4-10\n",
      "\n",
      "Loading required package: methods\n",
      "Warning message:\n",
      "replacing previous import by 'Rcpp::evalCpp' when loading 'later' \n",
      "Starting server to listen on port 8080\n",
      "Warning in if (stri_startswith_fixed(body, \"{\")) { :\n",
      "  the condition has length > 1 and only the first element will be used\n",
      "Warning in if (stri_startswith_fixed(qs, \"?\")) { :\n",
      "  the condition has length > 1 and only the first element will be used\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!docker run --rm --name 'my_rmars' \\\n",
    "    -p 8080:8080 \\\n",
    "    -v \"$PWD/model:/opt/ml/model\" \\\n",
    "    -v \"$PWD/input:/opt/ml/input\" sagemaker-rmars:1.0 serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While the above cell is running, click here [TEST NOTEBOOK](02_Testing%20our%20local%20model%20server.ipynb) to run some tests.\n",
    "\n",
    "> After you finish the tests, press **STOP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we push our code to the repo, let's check the building process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sts_client = boto3.client(\"sts\")\n",
    "session = boto3.session.Session()\n",
    "\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = session.region_name\n",
    "credentials = session.get_credentials()\n",
    "credentials = credentials.get_frozen_credentials()\n",
    "\n",
    "repo_name='sagemaker-rmars'\n",
    "image_tag='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat ‘model.py’: No such file or directory\n",
      "AWS_ACCOUNT_ID=607585071374\n",
      "IMAGE_TAG=test\n",
      "IMAGE_REPO_NAME=sagemaker-rmars\n",
      "AWS_DEFAULT_REGION=us-east-2\n",
      "AWS_ACCESS_KEY_ID=ASIAY25XEOEHOJZVJZRM\n",
      "AWS_SECRET_ACCESS_KEY=eVcjLZ6sSpai+1RFzExq1LBCQpBUI9myv12HwdFo\n",
      "AWS_SESSION_TOKEN=AgoJb3JpZ2luX2VjELj//////////wEaCXVzLWVhc3QtMiJHMEUCIQDSmqA9vZjHT80VwHw+Oc7ToOf28vNkl7sArQJ5LW27VQIgNAkxTn17plZEiMv5u1Mxn+1BObIRvvX14MYR6hZ9IFMq6wIIgv//////////ARAAGgw2MDc1ODUwNzEzNzQiDGNpHP2gUSeVQzWzriq/AqveepfRj9t1jaqUK/SKr4mQlMKCXq2FLrzIXjDZQnyw18cQPMkq2zG5OTE0FBogVYM1pZB40WieRv3cdahtY9MDiV7ZBhGa4mBMg45S9hyzdh10auFTp9gTGB/ZSnkCTuMko2q1omqVs2xVmc+/GBlpgCVsv2hlj7cPsk9Ngc0NxqtuZo6SW26aFkiHb0pUD7N3ynqy4wj8Twbb0UfJWstGGICE9i94IgCBWQjAgzs9BNd0ZLLojcncHpjr9kmYPQFM5yvV15JSp+ipCbqP85zq1iorTjQMCJPVpfe23AgacoZcHAfoHlEvIFUkC72eACokMdt7pTQXMpgxqjcqwHP5QfaWBVf35NuiZQUmCnfWtiZrm5O7lGHIaCvuzANaR2QPX9Eb+GlFIi6nuWUsl7k+yq2IrzpEIiKr4FR4s5kw3fWF7AU6tAHuvrJ085O4RUOxispojPyPQH9DyqiaJ49ZUC+xaIVkE++6H/B6LY78X4Edx2nKssFy7tWdOT0la9IqnLcN2brbPBJvNxoLDyziDDUlcZuvyYeophy5RzPKs/Iej01u8XkmWkBfwunZNZPC55PfR8WcaU9zNaoDDJkZSWbPBbq7bCFJP2qXLnTjTz/fIUNvTcPjtxkwUt9v4/+By/vkh2S20je/n9lSYyHwVNoWNKhhiXB2Xhk=\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p tests\n",
    "!cp model.py Dockerfile buildspec.yml tests/\n",
    "with open('tests/vars.env', 'w') as f:\n",
    "    f.write(\"AWS_ACCOUNT_ID=%s\\n\" % account_id)\n",
    "    f.write(\"IMAGE_TAG=%s\\n\" % image_tag)\n",
    "    f.write(\"IMAGE_REPO_NAME=%s\\n\" % repo_name)\n",
    "    f.write(\"AWS_DEFAULT_REGION=%s\\n\" % region)\n",
    "    f.write(\"AWS_ACCESS_KEY_ID=%s\\n\" % credentials.access_key)\n",
    "    f.write(\"AWS_SECRET_ACCESS_KEY=%s\\n\" % credentials.secret_key)\n",
    "    f.write(\"AWS_SESSION_TOKEN=%s\\n\" % credentials.token )\n",
    "    f.close()\n",
    "\n",
    "!cat tests/vars.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!/tmp/aws-codebuild/local_builds/codebuild_build.sh \\\n",
    "    -a \"$PWD/tests/output\" \\\n",
    "    -s \"$PWD/tests\" \\\n",
    "    -i \"samirsouza/aws-codebuild-standard:2.0\" \\\n",
    "    -e \"$PWD/tests/vars.env\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, now it's time to push everything to the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ../../../mlops-workshop-images/sagemaker-rmars\n",
    "cp $OLDPWD/buildspec.yml $OLDPWD/model.py $OLDPWD/Dockerfile .\n",
    "\n",
    "git add --all\n",
    "git commit -a -m \" - files for building an iris model image\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, now open the AWS console in another tab and go to the CodePipeline console to see the status of our building pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
