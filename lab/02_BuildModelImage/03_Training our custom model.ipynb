{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, we can start a new training job\n",
    "\n",
    "We'll send a zip file called **trainingjob.zip**, with the following structure:\n",
    " - trainingjob.json (Sagemaker training job descriptor)\n",
    " - monitoring.json (Sagemaker monitoring inputs for data capture, baseline and schedule)\n",
    " - assets/deploy-model-prd.yml (Cloudformation for deploying our model into Production)\n",
    " - assets/deploy-model-dev.yml (Cloudformation for deploying our model into Development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact bucket: mlops1-ap-southeast-2-691313291965\n",
      "image repo: mlops1-ludwig-model\n",
      "data bucket: sagemaker-ap-southeast-2-691313291965/text-multiclass\n",
      "role: arn:aws:iam::691313291965:role/mlops1-MLOps\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "sts_client = boto3.client(\"sts\")\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "artifact_bucket = os.environ['ARTIFACT_BUCKET']\n",
    "prefix = os.environ['MODEL_NAME']\n",
    "image_repo = os.environ['IMAGE_REPO']\n",
    "\n",
    "print('artifact bucket: {}'.format(artifact_bucket))\n",
    "print('image repo: {}'.format(image_repo))\n",
    "print('data bucket: {}/{}'.format(bucket, prefix))\n",
    "print('role: {}'.format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training job decriptor\n",
    "\n",
    "This includes some hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 128,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the training job image, and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = boto3.session.Session().region_name\n",
    "training_image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account_id, region, image_repo)\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = prefix + timestamp\n",
    "\n",
    "training_params = {}\n",
    "\n",
    "# Here we set the reference for the Image Classification Docker image, stored on ECR (https://aws.amazon.com/pt/ecr/)\n",
    "training_params[\"AlgorithmSpecification\"] = {\n",
    "    \"TrainingImage\": training_image,\n",
    "    \"TrainingInputMode\": \"File\",\n",
    "    \"MetricDefinitions\": [\n",
    "        {'Name':'train:loss', 'Regex':'Train Loss: (.*?);'},\n",
    "        {'Name':'train:accuracy', 'Regex':'Train Accuracy: (.*?)%;'},\n",
    "        {'Name':'val:loss', 'Regex':'Validation Loss: (.*?);'},\n",
    "        {'Name':'val:accuracy', 'Regex':'Validation Accuracy: (.*?)%;'},\n",
    "        {'Name':'test:loss', 'Regex':'Test Loss: (.*?);'},\n",
    "        {'Name':'test:accuracy', 'Regex':'Test Accuracy: (.*?)%;'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# The IAM role with all the permissions given to Sagemaker\n",
    "training_params[\"RoleArn\"] = role\n",
    "\n",
    "# Here Sagemaker will store the final trained model\n",
    "training_params[\"OutputDataConfig\"] = {\n",
    "    \"S3OutputPath\": 's3://{}/{}'.format(bucket, prefix)\n",
    "}\n",
    "\n",
    "# This is the config of the instance that will execute the training\n",
    "training_params[\"ResourceConfig\"] = {\n",
    "    \"InstanceCount\": 1,\n",
    "    \"InstanceType\": \"ml.m4.xlarge\",\n",
    "    \"VolumeSizeInGB\": 30\n",
    "}\n",
    "\n",
    "# The job name. You'll see this name in the Jobs section of the Sagemaker's console\n",
    "training_params[\"TrainingJobName\"] = job_name\n",
    "\n",
    "for i in hyperparameters:\n",
    "    hyperparameters[i] = str(hyperparameters[i])\n",
    "    \n",
    "# Here you will configure the hyperparameters used for training your model.\n",
    "training_params[\"HyperParameters\"] = hyperparameters\n",
    "\n",
    "# Training timeout\n",
    "training_params[\"StoppingCondition\"] = {\n",
    "    \"MaxRuntimeInSeconds\": 360000\n",
    "}\n",
    "\n",
    "# The algorithm currently only supports fullyreplicated model (where data is copied onto each machine)\n",
    "training_params[\"InputDataConfig\"] = [{\n",
    "    \"ChannelName\": \"training\",\n",
    "    \"DataSource\": {\n",
    "        \"S3DataSource\": {\n",
    "            \"S3DataType\": \"S3Prefix\",\n",
    "            \"S3Uri\": 's3://{}/{}/input/training'.format(bucket, prefix),\n",
    "            \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "        }\n",
    "    },\n",
    "    \"ContentType\": \"text/csv\",\n",
    "    \"CompressionType\": \"None\"\n",
    "},{\n",
    "    \"ChannelName\": \"validation\",\n",
    "    \"DataSource\": {\n",
    "        \"S3DataSource\": {\n",
    "            \"S3DataType\": \"S3Prefix\",\n",
    "            \"S3Uri\": 's3://{}/{}/input/validation'.format(bucket, prefix),\n",
    "            \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "        }\n",
    "    },\n",
    "    \"ContentType\": \"text/csv\",\n",
    "    \"CompressionType\": \"None\"\n",
    "}]\n",
    "training_params[\"Tags\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Upload training data\n",
    "\n",
    "Validate the training / test sets and upload these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: s3://sagemaker-ap-southeast-2-691313291965/text-multiclass/input/training\n",
      "validation: s3://sagemaker-ap-southeast-2-691313291965/text-multiclass/input/validation\n"
     ]
    }
   ],
   "source": [
    "train_loc = sagemaker_session.upload_data(path='input/data/training', key_prefix=prefix+'/input/training')\n",
    "val_loc = sagemaker_session.upload_data(path='input/data/validation', key_prefix=prefix+'/input/validation')\n",
    "\n",
    "print('training: {}'.format(train_loc))\n",
    "print('validation: {}'.format(val_loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure monitoring inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data capture config for endpoints\n",
    "\n",
    "1. Data Capture log output\n",
    "2. Baseline input location with file uploaded to s3\n",
    "3. Baseline results s3 location\n",
    "4. Schedule resports s3 location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data capture uri: s3://sagemaker-ap-southeast-2-691313291965/text-multiclass/datacapture\n"
     ]
    }
   ],
   "source": [
    "data_capture_uri = 's3://{}/{}/datacapture'.format(bucket, prefix)\n",
    "print('data capture uri: {}'.format(data_capture_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the output predictions from testing for baseline file.  Make sure we have headers on this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_predictions,class_probabilities_<UNK>,class_probabilities___label__eating_out,class_probabilities___label__groceries,class_probabilities___label__transport,class_probabilities___label__shopping,class_probabilities___label__health,class_probabilities___label__travel,class_probabilities___label__home,class_probabilities___label__entertainment,class_probabilities___label__education,class_probabilities___label__utilities,class_probabilities___label__fees_and_interest,class_probability\r\n",
      "__label__eating_out,0.0000000005,0.9998658895,0.0000015652,0.0000126153,0.0000005833,0.0000008130,0.0000364900,0.0000000217,0.0000022423,0.0000780779,0.0000013780,0.0000002604,0.9998658895\r\n"
     ]
    }
   ],
   "source": [
    "# Inspect the output predictions (NOTE: if using scientific format these will be treated as strings)\n",
    "baseline_file = 'output/data/predictions.csv'\n",
    "!head -2 $baseline_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the predictions as baseline file\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(baseline_file).upload_file(baseline_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline data file: s3://sagemaker-ap-southeast-2-691313291965/output/data/predictions.csv\n",
      "Baseline results uri: s3://sagemaker-ap-southeast-2-691313291965/text-multiclass/baselining/results\n"
     ]
    }
   ],
   "source": [
    "# copy over the training dataset to Amazon S3 (if you already have it in Amazon S3, you could reuse it)\n",
    "baseline_prefix = prefix + '/baselining'\n",
    "baseline_results_prefix = baseline_prefix + '/results'\n",
    "\n",
    "baseline_data_uri = 's3://{}/{}'.format(bucket,baseline_file)\n",
    "baseline_results_uri = 's3://{}/{}'.format(bucket, baseline_results_prefix)\n",
    "print('Baseline data file: {}'.format(baseline_data_uri))\n",
    "print('Baseline results uri: {}'.format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define the location for the monitor schedule outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monitoring reports: s3://sagemaker-ap-southeast-2-691313291965/text-multiclass/monitoring/reports\n"
     ]
    }
   ],
   "source": [
    "monitoring_reports_uri = 's3://{}/{}/monitoring/reports'.format(bucket, prefix)\n",
    "\n",
    "print('monitoring reports: {}'.format(monitoring_reports_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the training job hash so we can force update of deployment.\n",
    "\n",
    "Until AutoPublishCodeSha256 support to force Lambda redployment [see PR](https://github.com/awslabs/serverless-application-model/pull/1376) we need to update the lambda zip contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training hash: c4451471c545197521e890a5f2d8ca3512aa5ba55a8fb7d1911bfafe856ab65b\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import json\n",
    "\n",
    "training_hash = hashlib.sha256(json.dumps(training_params).encode('utf-8')).hexdigest()\n",
    "print('training hash: {}'.format(training_hash))\n",
    "\n",
    "# TEMP: Write a new file to the API directory to force refresh\n",
    "with open('../../api/training_hash.txt', 'w') as f:\n",
    "    f.write(training_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the training job and monitoring json files as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_params = {\n",
    "    'TrainSha256': training_hash,\n",
    "    'DataCaptureUri': data_capture_uri,\n",
    "    'MonitoringRoleArn': role,\n",
    "    'BaselineInputUri': baseline_data_uri,\n",
    "    'BaselineResultsUri':  baseline_results_uri,\n",
    "    'ScheduleReportsUri': monitoring_reports_uri,\n",
    "    'ScheduleMetricName': 'feature_baseline_drift_class_predictions', # alarm on class predictions drift\n",
    "    'ScheduleMetricThreshold': str(0.4) # Must serialize parameters as string\n",
    "}\n",
    "\n",
    "with open('trainingjob.json', 'w') as f:\n",
    "    json.dump(training_params, f)\n",
    "with open('monitoring.json', 'w') as f:\n",
    "    json.dump(monitoring_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload deployment artifacts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the cloud formation template with API serverless endpoints uploading code to sagemaker bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to 4ac858bfeddfc6e8b20ccd34f5adb8e1  2873 / 2873.0  (100.00%)\n",
      "Successfully packaged artifacts and wrote output template to file ../../assets/template-model-prd.yml.\n",
      "Execute the following command to deploy the packaged template\n",
      "aws cloudformation deploy --template-file /home/ec2-user/SageMaker/mlops-workshop/assets/template-model-prd.yml --stack-name <YOUR STACK NAME>\n"
     ]
    }
   ],
   "source": [
    "!aws cloudformation package --template-file ../../assets/deploy-model-prd.yml \\\n",
    "    --output-template-file ../../assets/template-model-prd.yml --s3-bucket $artifact_bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the template has been generated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform: AWS::Serverless-2016-10-31\r\n",
      "Description: Deploy a model at Sagemaker\r\n",
      "Parameters:\r\n",
      "  ImageRepoName:\r\n",
      "    Type: String\r\n",
      "    Description: Name of the model image ECR (Docker) repo\r\n",
      "  ImageTagName:\r\n",
      "    Type: String\r\n",
      "    Description: Name of the model image ECR (Docker) tag\r\n",
      "  ModelName:\r\n",
      "    Type: String\r\n",
      "    Description: Name of the model\r\n",
      "  TrainJobId:\r\n",
      "    Type: String\r\n",
      "    Description: Id of the Codepipeline + SagemakerJobs\r\n",
      "  TrainSha256:\r\n",
      "    Type: String\r\n",
      "    Description: The Sha256 hash of the training job info\r\n",
      "  DataCaptureUri:\r\n",
      "    Type: String\r\n",
      "    Description: The s3 uri to upload data capture logs\r\n",
      "  MonitoringRoleArn:\r\n",
      "    Type: String\r\n",
      "    Description: The role for executing the monitoring schedule\r\n",
      "  BaselineInputUri:\r\n",
      "    Type: String\r\n",
      "    Description: The s3 uri for baseline input\r\n",
      "  BaselineResultsUri:\r\n",
      "    Type: String\r\n",
      "    Description: The s3 uri for storing baseline results\r\n",
      "  ScheduleReportsUri:\r\n",
      "    Type: String\r\n",
      "    Description: The s3 uri to schedule reports\r\n",
      "  ScheduleMetricName:\r\n",
      "    Type: String\r\n",
      "    Description: The metric to alarm on for schedule\r\n",
      "  ScheduleMetricThreshold:\r\n",
      "    Type: Number\r\n",
      "    Description: The metric alarm threshold\r\n",
      "Resources:\r\n",
      "  Model:\r\n",
      "    Type: AWS::SageMaker::Model\r\n",
      "    Properties:\r\n",
      "      ModelName:\r\n",
      "        Fn::Sub: mlops-${ModelName}-prd-${TrainJobId}\r\n",
      "      PrimaryContainer:\r\n",
      "        Image:\r\n",
      "          Fn::Sub: ${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/${ImageRepoName}:${ImageTagName}\r\n",
      "        ModelDataUrl:\r\n",
      "          Fn::Sub: s3://sagemaker-${AWS::Region}-${AWS::AccountId}/${ModelName}/mlops-${ModelName}-${TrainJobId}/output/model.tar.gz\r\n",
      "      ExecutionRoleArn:\r\n",
      "        Fn::Sub: arn:aws:iam::${AWS::AccountId}:role/MLOps\r\n",
      "  EndpointConfig:\r\n",
      "    Type: AWS::SageMaker::EndpointConfig\r\n",
      "    Properties:\r\n",
      "      ProductionVariants:\r\n",
      "      - InitialInstanceCount: 2\r\n",
      "        InitialVariantWeight: 1.0\r\n",
      "        InstanceType: ml.c5.large\r\n",
      "        ModelName:\r\n",
      "          Fn::GetAtt:\r\n",
      "          - Model\r\n",
      "          - ModelName\r\n",
      "        VariantName: AllTraffic\r\n",
      "      EndpointConfigName:\r\n",
      "        Fn::Sub: mlops-${ModelName}-pec-${TrainJobId}\r\n",
      "      Tags:\r\n",
      "      - Key: Name\r\n",
      "        Value:\r\n",
      "          Fn::Sub: mlops-${ModelName}-pec-${TrainJobId}\r\n",
      "  Endpoint:\r\n",
      "    Type: AWS::SageMaker::Endpoint\r\n",
      "    Properties:\r\n",
      "      EndpointName:\r\n",
      "        Fn::Sub: mlops-${ModelName}-prd-${TrainJobId}\r\n",
      "      EndpointConfigName:\r\n",
      "        Fn::GetAtt:\r\n",
      "        - EndpointConfig\r\n",
      "        - EndpointConfigName\r\n",
      "      Tags:\r\n",
      "      - Key: Name\r\n",
      "        Value:\r\n",
      "          Fn::Sub: mlops-${ModelName}-prd-${TrainJobId}\r\n",
      "    DependsOn: EndpointConfig\r\n",
      "  SagemakerDataCapture:\r\n",
      "    Type: Custom::EnableDataCapture\r\n",
      "    Properties:\r\n",
      "      ServiceToken:\r\n",
      "        Fn::Sub: arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:sagemaker-cfn-enable-data-capture\r\n",
      "      EndpointName:\r\n",
      "        Fn::GetAtt:\r\n",
      "        - Endpoint\r\n",
      "        - EndpointName\r\n",
      "      VariantName: AllTraffic\r\n",
      "      EndpointConfigName:\r\n",
      "        Fn::Sub: mlops-${ModelName}-pdc-${TrainJobId}\r\n",
      "      DataCaptureUri:\r\n",
      "        Ref: DataCaptureUri\r\n",
      "    DependsOn: Endpoint\r\n",
      "  DeploymentCompleteTopic:\r\n",
      "    Type: AWS::SNS::Topic\r\n",
      "    Properties:\r\n",
      "      TopicName:\r\n",
      "        Fn::Sub: mlops-${ModelName}-deployment\r\n",
      "  ApiFunction:\r\n",
      "    Type: AWS::Serverless::Function\r\n",
      "    Properties:\r\n",
      "      FunctionName:\r\n",
      "        Fn::Sub: mlops-${ModelName}-api\r\n",
      "      CodeUri: s3://mlops1-ap-southeast-2-691313291965/4ac858bfeddfc6e8b20ccd34f5adb8e1\r\n",
      "      Handler: app.lambda_handler\r\n",
      "      Runtime: python3.7\r\n",
      "      Role:\r\n",
      "        Fn::GetAtt:\r\n",
      "        - ApiFunctionRole\r\n",
      "        - Arn\r\n",
      "      AutoPublishAlias: live\r\n",
      "      DeploymentPreference:\r\n",
      "        Type: Canary10Percent5Minutes\r\n",
      "        Alarms:\r\n",
      "        - Ref: AliasErrorMetricGreaterThanZeroAlarm\r\n",
      "        - Ref: LatestVersionErrorMetricGreaterThanZeroAlarm\r\n",
      "        Hooks:\r\n",
      "          PreTraffic:\r\n",
      "            Ref: PreTrafficLambdaFunction\r\n",
      "          PostTraffic:\r\n",
      "            Ref: PostTrafficLambdaFunction\r\n",
      "        TriggerConfigurations:\r\n",
      "        - TriggerEvents:\r\n",
      "          - DeploymentSuccess\r\n",
      "          - DeploymentFailure\r\n",
      "          TriggerName: DeploymentCompleteTrigger\r\n",
      "          TriggerTargetArn:\r\n",
      "            Ref: DeploymentCompleteTopic\r\n",
      "      Environment:\r\n",
      "        Variables:\r\n",
      "          ENDPOINT_NAME:\r\n",
      "            Fn::GetAtt:\r\n",
      "            - Endpoint\r\n",
      "            - EndpointName\r\n",
      "      Events:\r\n",
      "        Invoke:\r\n",
      "          Type: Api\r\n",
      "          Properties:\r\n",
      "            Path: /api\r\n",
      "            Method: post\r\n",
      "    DependsOn: SagemakerDataCapture\r\n",
      "    Description: Api deployment that invokes SagemMaker endpoint\r\n",
      "  ApiFunctionRole:\r\n",
      "    Type: AWS::IAM::Role\r\n",
      "    Properties:\r\n",
      "      AssumeRolePolicyDocument:\r\n",
      "        Statement:\r\n",
      "        - Action:\r\n",
      "          - sts:AssumeRole\r\n",
      "          Effect: Allow\r\n",
      "          Principal:\r\n",
      "            Service:\r\n",
      "            - lambda.amazonaws.com\r\n",
      "        Version: '2012-10-17'\r\n",
      "      ManagedPolicyArns:\r\n",
      "      - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\r\n",
      "      Policies:\r\n",
      "      - PolicyDocument:\r\n",
      "          Statement:\r\n",
      "          - Sid: AllowSageMaker\r\n",
      "            Effect: Allow\r\n",
      "            Action:\r\n",
      "            - sagemaker:InvokeEndpoint\r\n",
      "            Resource: arn:aws:sagemaker:*:*:endpoint/*\r\n",
      "          Version: '2012-10-17'\r\n",
      "        PolicyName: SageMakerInvokeEndpoint\r\n",
      "  PreTrafficLambdaFunction:\r\n",
      "    Type: AWS::Serverless::Function\r\n",
      "    Properties:\r\n",
      "      FunctionName:\r\n",
      "        Fn::Sub: CodeDeployHook_mlops-${ModelName}-PreTrafficLambdaFunction\r\n",
      "      CodeUri: s3://mlops1-ap-southeast-2-691313291965/4ac858bfeddfc6e8b20ccd34f5adb8e1\r\n",
      "      Handler: pre_traffic_hook.lambda_handler\r\n",
      "      Runtime: python3.7\r\n",
      "      Policies:\r\n",
      "      - Version: '2012-10-17'\r\n",
      "        Statement:\r\n",
      "        - Sid: AllowSageMaker\r\n",
      "          Effect: Allow\r\n",
      "          Action:\r\n",
      "          - sagemaker:DescribeEndpoint\r\n",
      "          Resource: arn:aws:sagemaker:*:*:endpoint/*\r\n",
      "        - Sid: AllowCodeDeploy\r\n",
      "          Effect: Allow\r\n",
      "          Action:\r\n",
      "          - codedeploy:PutLifecycleEventHookExecutionStatus\r\n",
      "          Resource:\r\n",
      "            Fn::Sub: arn:${AWS::Partition}:codedeploy:${AWS::Region}:${AWS::AccountId}:deploymentgroup:${ServerlessDeploymentApplication}/*\r\n",
      "      DeploymentPreference:\r\n",
      "        Enabled: false\r\n",
      "      Environment:\r\n",
      "        Variables:\r\n",
      "          ENDPOINT_NAME:\r\n",
      "            Fn::GetAtt:\r\n",
      "            - Endpoint\r\n",
      "            - EndpointName\r\n",
      "          DATA_CAPTURE_URI:\r\n",
      "            Ref: DataCaptureUri\r\n",
      "      Description: Perform checks pre-shifting traffic to lambda\r\n",
      "  PostTrafficLambdaFunction:\r\n",
      "    Type: AWS::Serverless::Function\r\n",
      "    Properties:\r\n",
      "      FunctionName:\r\n",
      "        Fn::Sub: CodeDeployHook_mlops-${ModelName}-PostTrafficLambdaFunction\r\n",
      "      CodeUri: s3://mlops1-ap-southeast-2-691313291965/4ac858bfeddfc6e8b20ccd34f5adb8e1\r\n",
      "      Handler: post_traffic_hook.lambda_handler\r\n",
      "      Runtime: python3.7\r\n",
      "      Policies:\r\n",
      "      - Version: '2012-10-17'\r\n",
      "        Statement:\r\n",
      "        - Sid: AllowCodeDeploy\r\n",
      "          Effect: Allow\r\n",
      "          Action:\r\n",
      "          - codedeploy:PutLifecycleEventHookExecutionStatus\r\n",
      "          Resource:\r\n",
      "            Fn::Sub: arn:${AWS::Partition}:codedeploy:${AWS::Region}:${AWS::AccountId}:deploymentgroup:${ServerlessDeploymentApplication}/*\r\n",
      "      DeploymentPreference:\r\n",
      "        Enabled: false\r\n",
      "      Environment:\r\n",
      "        Variables:\r\n",
      "          ENDPOINT_NAME:\r\n",
      "            Fn::GetAtt:\r\n",
      "            - Endpoint\r\n",
      "            - EndpointName\r\n",
      "          DATA_CAPTURE_URI:\r\n",
      "            Ref: DataCaptureUri\r\n",
      "      Description: Perform checks post-shifting traffic to lambda\r\n",
      "  SagemakerSuggestBaseline:\r\n",
      "    Type: Custom::SuggestBaseline\r\n",
      "    Properties:\r\n",
      "      ServiceToken:\r\n",
      "        Fn::Sub: arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:sagemaker-cfn-suggest-baseline\r\n",
      "      ProcessingJobName:\r\n",
      "        Fn::Sub: mlops-${ModelName}-pbl-${TrainJobId}\r\n",
      "      BaselineInputUri:\r\n",
      "        Ref: BaselineInputUri\r\n",
      "      BaselineResultsUri:\r\n",
      "        Ref: BaselineResultsUri\r\n",
      "      PassRoleArn:\r\n",
      "        Ref: MonitoringRoleArn\r\n",
      "  SagemakerMonitoringSchedule:\r\n",
      "    Type: Custom::MonitoringSchedule\r\n",
      "    Properties:\r\n",
      "      ServiceToken:\r\n",
      "        Fn::Sub: arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:sagemaker-cfn-monitoring-schedule\r\n",
      "      EndpointName:\r\n",
      "        Fn::GetAtt:\r\n",
      "        - Endpoint\r\n",
      "        - EndpointName\r\n",
      "      ScheduleName:\r\n",
      "        Fn::Sub: mlops-${ModelName}-pms-${TrainJobId}\r\n",
      "      BaselineConstraintsUri:\r\n",
      "        Fn::GetAtt:\r\n",
      "        - SagemakerSuggestBaseline\r\n",
      "        - BaselineConstraintsUri\r\n",
      "      BaselineStatisticsUri:\r\n",
      "        Fn::GetAtt:\r\n",
      "        - SagemakerSuggestBaseline\r\n",
      "        - BaselineStatisticsUri\r\n",
      "      OutputS3URI:\r\n",
      "        Ref: ScheduleReportsUri\r\n",
      "      PassRoleArn:\r\n",
      "        Ref: MonitoringRoleArn\r\n",
      "    DependsOn: SagemakerDataCapture\r\n",
      "  SagemakerScheduleAlarm:\r\n",
      "    Type: AWS::CloudWatch::Alarm\r\n",
      "    Properties:\r\n",
      "      AlarmName:\r\n",
      "        Fn::Sub: mlops-${ModelName}-metric-gt-threshold\r\n",
      "      AlarmDescription: Schedule Metric > Threshold\r\n",
      "      ComparisonOperator: GreaterThanThreshold\r\n",
      "      Dimensions:\r\n",
      "      - Name: Endpoint\r\n",
      "        Value:\r\n",
      "          Fn::GetAtt:\r\n",
      "          - Endpoint\r\n",
      "          - EndpointName\r\n",
      "      - Name: MonitoringSchedule\r\n",
      "        Value:\r\n",
      "          Fn::GetAtt:\r\n",
      "          - SagemakerMonitoringSchedule\r\n",
      "          - ScheduleName\r\n",
      "      EvaluationPeriods: 2\r\n",
      "      MetricName:\r\n",
      "        Ref: ScheduleMetricName\r\n",
      "      Namespace: aws/sagemaker/Endpoints/data-metrics\r\n",
      "      Period: 60\r\n",
      "      Statistic: Sum\r\n",
      "      Threshold:\r\n",
      "        Ref: ScheduleMetricThreshold\r\n",
      "  AliasErrorMetricGreaterThanZeroAlarm:\r\n",
      "    Type: AWS::CloudWatch::Alarm\r\n",
      "    Properties:\r\n",
      "      AlarmName:\r\n",
      "        Fn::Sub: mlops-${ModelName}-alias-gt-zero\r\n",
      "      AlarmDescription: Lambda Function Error > 0\r\n",
      "      ComparisonOperator: GreaterThanThreshold\r\n",
      "      Dimensions:\r\n",
      "      - Name: Resource\r\n",
      "        Value:\r\n",
      "          Fn::Sub: ${ApiFunction}:live\r\n",
      "      - Name: FunctionName\r\n",
      "        Value:\r\n",
      "          Ref: ApiFunction\r\n",
      "      EvaluationPeriods: 2\r\n",
      "      MetricName: Errors\r\n",
      "      Namespace: AWS/Lambda\r\n",
      "      Period: 60\r\n",
      "      Statistic: Sum\r\n",
      "      Threshold: 0\r\n",
      "  LatestVersionErrorMetricGreaterThanZeroAlarm:\r\n",
      "    Type: AWS::CloudWatch::Alarm\r\n",
      "    Properties:\r\n",
      "      AlarmName:\r\n",
      "        Fn::Sub: mlops-${ModelName}-version-gt-zero\r\n",
      "      AlarmDescription: Lambda Function Error > 0\r\n",
      "      ComparisonOperator: GreaterThanThreshold\r\n",
      "      Dimensions:\r\n",
      "      - Name: Resource\r\n",
      "        Value:\r\n",
      "          Fn::Sub: ${ApiFunction}:live\r\n",
      "      - Name: FunctionName\r\n",
      "        Value:\r\n",
      "          Ref: ApiFunction\r\n",
      "      - Name: ExecutedVersion\r\n",
      "        Value:\r\n",
      "          Fn::GetAtt:\r\n",
      "          - ApiFunction\r\n",
      "          - Version.Version\r\n",
      "      EvaluationPeriods: 2\r\n",
      "      MetricName: Errors\r\n",
      "      Namespace: AWS/Lambda\r\n",
      "      Period: 60\r\n",
      "      Statistic: Sum\r\n",
      "      Threshold: 0\r\n",
      "  AutoScaling:\r\n",
      "    Type: AWS::ApplicationAutoScaling::ScalableTarget\r\n",
      "    Properties:\r\n",
      "      MaxCapacity: 10\r\n",
      "      MinCapacity: 2\r\n",
      "      ResourceId:\r\n",
      "        Fn::Sub: endpoint/mlops-${ModelName}-prd-${TrainJobId}/variant/AllTraffic\r\n",
      "      RoleARN:\r\n",
      "        Fn::Sub: arn:aws:iam::${AWS::AccountId}:role/MLOps\r\n",
      "      ScalableDimension: sagemaker:variant:DesiredInstanceCount\r\n",
      "      ServiceNamespace: sagemaker\r\n",
      "    DependsOn: ApiFunction\r\n",
      "  AutoScalingPolicy:\r\n",
      "    Type: AWS::ApplicationAutoScaling::ScalingPolicy\r\n",
      "    Properties:\r\n",
      "      PolicyName: SageMakerVariantInvocationsPerInstance\r\n",
      "      PolicyType: TargetTrackingScaling\r\n",
      "      ResourceId:\r\n",
      "        Fn::Sub: endpoint/mlops-${ModelName}-prd-${TrainJobId}/variant/AllTraffic\r\n",
      "      ScalableDimension: sagemaker:variant:DesiredInstanceCount\r\n",
      "      ServiceNamespace: sagemaker\r\n",
      "      TargetTrackingScalingPolicyConfiguration:\r\n",
      "        TargetValue: 750.0\r\n",
      "        ScaleInCooldown: 60\r\n",
      "        ScaleOutCooldown: 60\r\n",
      "        PredefinedMetricSpecification:\r\n",
      "          PredefinedMetricType: SageMakerVariantInvocationsPerInstance\r\n",
      "    DependsOn: AutoScaling\r\n",
      "Outputs:\r\n",
      "  DeploymentApplication:\r\n",
      "    Description: Regression deployment application\r\n",
      "    Value:\r\n",
      "      Ref: ServerlessDeploymentApplication\r\n",
      "  RestApi:\r\n",
      "    Description: API Gateway endpoint URL for Prod stage for Regression function\r\n",
      "    Value:\r\n",
      "      Fn::Sub: https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/api/\r\n",
      "  DataCaptureEndpointUri:\r\n",
      "    Description: The base uri for data capture logs\r\n",
      "    Value:\r\n",
      "      Fn::GetAtt:\r\n",
      "      - SagemakerDataCapture\r\n",
      "      - DataCaptureEndpointUri\r\n",
      "  ProcessingJobName:\r\n",
      "    Description: The name of the baseline processing job\r\n",
      "    Value:\r\n",
      "      Fn::GetAtt:\r\n",
      "      - SagemakerSuggestBaseline\r\n",
      "      - ProcessingJobName\r\n",
      "  ScheduleName:\r\n",
      "    Description: The name of the monitoring schedule\r\n",
      "    Value:\r\n",
      "      Fn::GetAtt:\r\n",
      "      - SagemakerMonitoringSchedule\r\n",
      "      - ScheduleName\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../../assets/template-model-prd.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, now it's time to push everything to the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 72508e3]  - test updated deployment\n",
      " 3 files changed, 5 insertions(+), 5 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://git-codecommit.ap-southeast-2.amazonaws.com/v1/repos/mlops1-text-multiclass\n",
      "   2f88799..72508e3  master -> master\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd ../../../mlops-workshop-images/master\n",
    "mkdir -p assets\n",
    "\n",
    "cp $OLDPWD/trainingjob.json $OLDPWD/monitoring.json .\n",
    "cp ../../mlops-workshop/assets/template-model-prd.yml assets/deploy-model-prd.yml  # Save as original name\n",
    "cp ../../mlops-workshop/assets/deploy-model-dev.yml assets/deploy-model-dev.yml\n",
    "cp ../../mlops-workshop/assets/wait-training-job.yml assets/wait-training-job.yml\n",
    "\n",
    "git add --all\n",
    "git commit -a -m \" - test updated deployment\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, now open the AWS console in another tab and go to the CodePipeline console to see the status of our building pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finally, click here [NOTEBOOK](04_Check%20Progress%20and%20Test%20the%20endpoint.ipynb) to see the progress and test your endpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
