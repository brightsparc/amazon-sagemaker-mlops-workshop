{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's monitor the training/deploying process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions():\n",
    "    actions = []\n",
    "    executionId = None\n",
    "    resp = codepipeline.get_pipeline_state( name=pipeline_name )\n",
    "    for stage in resp['stageStates']:\n",
    "        stageName = stage['stageName']\n",
    "        stageStatus = None\n",
    "        if stage.get('latestExecution') is not None:\n",
    "            stageStatus = stage['latestExecution']['status']\n",
    "            if executionId is None:\n",
    "                executionId = stage['latestExecution']['pipelineExecutionId']\n",
    "            elif stage['latestExecution']['pipelineExecutionId'] != executionId:\n",
    "                stageStatus = 'Old'\n",
    "        for action in stage['actionStates']:\n",
    "            actionName = action['actionName']\n",
    "            actionStatus = 'Old'\n",
    "            if action.get('latestExecution') is not None and stageStatus != 'Old':\n",
    "                actionStatus = action['latestExecution']['status']\n",
    "            actions.append( {'stageName': stageName, \n",
    "                             'stageStatus': stageStatus, \n",
    "                             'actionName': actionName, \n",
    "                             'actionStatus': actionStatus})\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_approval_token():\n",
    "    resp = codepipeline.get_pipeline_state( name=pipeline_name )\n",
    "    token = None\n",
    "    # Get the approve train status token\n",
    "    for stageState in resp['stageStates']:\n",
    "        if stageState['stageName'] == 'DeployDev':\n",
    "            for actionState in stageState['actionStates']:\n",
    "                if actionState['actionName'] == 'ApproveDeploy':\n",
    "                    if actionState.get('latestExecution') is None:\n",
    "                        return None\n",
    "                    latestExecution = actionState['latestExecution']\n",
    "                    if latestExecution['status'] == 'InProgress':\n",
    "                        token = latestExecution['token']\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approval(token, result):\n",
    "    if token is None:\n",
    "        return\n",
    "    \n",
    "    codepipeline.put_approval_result(\n",
    "      pipelineName=pipeline_name,\n",
    "      stageName='DeployDev',\n",
    "      actionName='ApproveDeploy',\n",
    "      result=result,\n",
    "      token=token\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approve(b):\n",
    "    result={\n",
    "        'summary': 'This is a great model! Put into production.',\n",
    "        'status': 'Approved'\n",
    "    }\n",
    "    approval(get_approval_token(), result) \n",
    "    button_box.close()\n",
    "    start_monitoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject(b):\n",
    "    result={\n",
    "        'summary': 'This is a rubbish model. Discard it',\n",
    "        'status': 'Rejected'\n",
    "    }\n",
    "    approval(get_approval_token(), result)\n",
    "    button_box.close()\n",
    "    start_monitoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_monitoring():\n",
    "    global button_box\n",
    "    \n",
    "    running = True\n",
    "    while running:\n",
    "        steps_ok = 0\n",
    "        for k,action in enumerate(get_actions()):\n",
    "            if action['actionStatus'] == 'Failed':\n",
    "                bar.bar_style='danger'\n",
    "                label.value='Ops! Something went wrong Stage[{}] Action[{}]'.format(\n",
    "                    action['stageName'], action['actionName'])\n",
    "                running = False\n",
    "                return\n",
    "\n",
    "            elif action['actionStatus'] == 'InProgress':\n",
    "                if get_approval_token() is not None:\n",
    "                    display(button_box)\n",
    "                    running = False\n",
    "                break\n",
    "            elif action['actionStatus'] == 'Old':\n",
    "                break\n",
    "            elif action['actionStatus'] == 'Succeeded':\n",
    "                steps_ok += 1\n",
    "        \n",
    "        label.value = \"Actions {}/{} - Current: Stage[{}] Action[{}]\".format( \n",
    "                k+1,max_actions, action['stageName'], action['actionName'] )\n",
    "        bar.value = steps_ok\n",
    "\n",
    "        if steps_ok == max_actions:\n",
    "            running = False\n",
    "        else:    \n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "codepipeline = boto3.client('codepipeline')\n",
    "pipeline_name = os.environ['PIPELINE_NAME']\n",
    "model_name = os.environ['MODEL_NAME']\n",
    "\n",
    "print('pipeline: {}'.format(pipeline_name))\n",
    "print('model name: {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approve_btn = widgets.Button(description=\"Approve\", button_style='success', icon='check')\n",
    "reject_btn = widgets.Button(description=\"Reject\", button_style='danger', icon='close')\n",
    "approve_btn.on_click(approve)\n",
    "reject_btn.on_click(reject)\n",
    "button_box = widgets.HBox([approve_btn, reject_btn])\n",
    "                \n",
    "max_actions = len(get_actions())\n",
    "label = widgets.Label(value=\"Loading...\")\n",
    "bar = widgets.IntProgress( value=0, min=0, max=max_actions, step=1, bar_style='info' )\n",
    "info_box = widgets.VBox([label, bar])\n",
    "\n",
    "display(info_box)\n",
    "start_monitoring()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, if everything went fine, we can test our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current execution id, and production endpoints\n",
    "response = codepipeline.get_pipeline_state( name=pipeline_name )\n",
    "executionId = response['stageStates'][-1]['latestExecution']['pipelineExecutionId']\n",
    "\n",
    "endpoint_name='mlops-{}-prd-{}'.format(model_name, executionId)\n",
    "processing_job_name='mlops-{}-pbl-{}'.format(model_name, executionId)\n",
    "schedule_name='mlops-{}-pms-{}'.format(model_name, executionId)\n",
    "\n",
    "print('execution id: {}'.format(executionId))\n",
    "print('endpoint name: {}'.format(endpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the endpoint with some expected, and unexpected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "def test_endpoint(endpoint_name, payload, content_type='text/csv', custom_attributes=''):\n",
    "    resp = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=payload,\n",
    "        ContentType=content_type,\n",
    "        CustomAttributes=custom_attributes\n",
    "    )\n",
    "    return resp['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that we can send some traffic to the end point\n",
    "test_endpoint(endpoint_name, 'text\\nthis is a test'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Endpoint\n",
    "\n",
    "Send a bunch of examples to the endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "monitor_sample = [\n",
    "# Define some typical data\n",
    "#     'cool asian food pty melbourne au', # eathing out\n",
    "#     'woolworths 3188 brunswick au', # groceries\n",
    "#     'airbnb * blaa surry hills au', # travel\n",
    "#     'lido cinemas hawthorn au', # entertainment\n",
    "#     'northcote indoor spo thornbury au', # health\n",
    "# Define some data which is out of bounds of usual sample\n",
    "    'one',\n",
    "    '1',\n",
    "    'fdkslfjkdlsjfkdsfkldjsklfmdskfjkdlsjfkldsjfkldsjfkldsjklfjsdkjfklds',\n",
    "    'this is a very long sentance that should skew the character and word count',\n",
    "]\n",
    "\n",
    "# Send off a series of invidual requests for each sample\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(100)):\n",
    "    for sample in monitor_sample:\n",
    "        payload = 'text\\n{}'.format(sample).encode('utf-8')\n",
    "        test_endpoint(endpoint_name, payload).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production deployment\n",
    "\n",
    "List progress on this cloud formation stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "stack_name = stack_name='{}-deploy-prd'.format(pipeline_name)\n",
    "print('stack name: {}'.format(stack_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = cfn.describe_stacks(StackName=stack_name)\n",
    "if response['Stacks']:\n",
    "    stack = response['Stacks'][0]\n",
    "    print('stack status: {}'.format(stack['StackStatus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the last events and how long ago they occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "\n",
    "def get_event_dataframe(events):\n",
    "    stack_cols = ['LogicalResourceId', 'ResourceStatus', 'ResourceStatusReason', 'Timestamp']\n",
    "    stack_event_df = pd.DataFrame(events)[stack_cols].fillna('')\n",
    "    stack_event_df['TimeAgo'] = (datetime.now(tzlocal())-stack_event_df['Timestamp'])\n",
    "    return stack_event_df.drop('Timestamp', axis=1)\n",
    "\n",
    "# Get latest stack events\n",
    "response = cfn.describe_stack_events(StackName=stack_name)\n",
    "get_event_dataframe(response['StackEvents']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\" rel=\"noopener noreferrer\" target=\"_blank\">link</a>'.format(val,val)\n",
    "\n",
    "def get_resource_dataframe(resources):\n",
    "    resource_map = {\n",
    "        'AWS::Lambda::Function': 'https://{0}.console.aws.amazon.com/lambda/home?region={0}#functions/{1}',\n",
    "        'AWS::CodeDeploy::Application': 'https://{0}.console.aws.amazon.com/codesuite/codedeploy/applications/{1}?region={0}',\n",
    "        'AWS::ApiGateway::RestApi': 'https://{0}.console.aws.amazon.com/apigateway/home?region={0}#/apis/{1}/resources',\n",
    "        'AWS::SageMaker::Endpoint': 'https://{0}.console.aws.amazon.com/sagemaker/home?region={0}#/endpoints/{1}'\n",
    "    }\n",
    "    resources = [\n",
    "        {\n",
    "            'name': r['LogicalResourceId'],\n",
    "            'url': resource_map[r['ResourceType']].format(region, r['PhysicalResourceId'].split('/')[-1]),\n",
    "            'type': r['ResourceType'],\n",
    "            'status': r['ResourceStatus']\n",
    "        } for r in resources\n",
    "        if (r['ResourceType'] in resource_map and r['ResourceStatus'] in ['CREATE_COMPLETE', 'UPDATE_COMPLETE'])\n",
    "    ]\n",
    "    cols = ['name', 'type', 'status', 'url']\n",
    "    df = pd.DataFrame(resources)[cols]\n",
    "    return df.style.format({'url': make_clickable})\n",
    "\n",
    "# Get resource list\n",
    "response = cfn.describe_stack_resources(StackName=stack_name)\n",
    "get_resource_dataframe(response['StackResources'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Lambda API\n",
    "\n",
    "Send a message to the API endpoint, and check the endpoint name included in the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add loop to call API endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load baseline\n",
    "\n",
    "Load baseline processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.model_monitor import BaseliningJob, DefaultModelMonitor, MonitoringExecution\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "sm = boto3.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = BaseliningJob.from_processing_name(sagemaker_session, processing_job_name)\n",
    "status = baseline_job.describe()['ProcessingJobStatus']\n",
    "if status != 'Completed':\n",
    "    raise(Exception('Processing job not complete, status: {}'.format(status)))\n",
    "    \n",
    "baseline_results_uri  = baseline_job.outputs[0].destination\n",
    "print('baseline results uri: {}'.format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $baseline_results_uri/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the generated constraints and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df = pd.io.json.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_df = pd.io.json.json_normalize(baseline_job.suggested_constraints().body_dict[\"features\"])\n",
    "constraints_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Data Capture\n",
    "\n",
    "Get the list of data capture files form the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker.Session().default_bucket()\n",
    "data_capture_logs_uri = 's3://{}/{}/datacapture/{}'.format(bucket, model_name, endpoint_name)\n",
    "\n",
    "print('Data Capture logs: {}'.format(data_capture_logs_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_files = S3Downloader.list(data_capture_logs_uri)\n",
    "print('Found {} files'.format(len(capture_files)))\n",
    "\n",
    "if capture_files:\n",
    "    # Get the first line of the most recent file    \n",
    "    event = json.loads(S3Downloader.read_file(capture_files[-1]).split('\\n')[0])\n",
    "    print('\\nLast file:\\n{}'.format(json.dumps(event, indent=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Monitoring Schedule\n",
    "\n",
    "The functions for plotting and rendering distribution statistics or constraint violations are implemented in a `utils` file so let's grab that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O utils.py --quiet https://raw.githubusercontent.com/awslabs/amazon-sagemaker-examples/master/sagemaker_model_monitor/visualization/utils.py\n",
    "import utils as mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the last succesful monitoring schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that we are looking for completed/stopped schedules\n",
    "response = sm.list_monitoring_executions(MonitoringScheduleName=schedule_name)\n",
    "\n",
    "status = None\n",
    "expected_status = ['Completed', 'CompletedWithViolations']\n",
    "for mon in response['MonitoringExecutionSummaries']:\n",
    "    processing_job_arn = mon['ProcessingJobArn']\n",
    "    status = mon['MonitoringExecutionStatus']\n",
    "    if status in expected_status:\n",
    "        break\n",
    "\n",
    "if not status in expected_status:\n",
    "    raise(Exception('No completed schedules'))\n",
    "    \n",
    "print('Schedule status: {}'.format(status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the monitoring execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = MonitoringExecution.from_processing_arn(sagemaker_session=sagemaker.Session(), \n",
    "                                                    processing_job_arn=processing_job_arn)\n",
    "exec_inputs = {inp['InputName']: inp for inp in execution.describe()['ProcessingInputs']}\n",
    "exec_results_uri = execution.output.destination\n",
    "\n",
    "print('Monitoring Execution results: {}'.format(exec_results_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the constraints, statistics and violations if they exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $exec_results_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the baseline and monitoring statistics & violations\n",
    "baseline_statistics = baseline_job.baseline_statistics().body_dict\n",
    "execution_statistics = execution.statistics().body_dict\n",
    "violations = execution.constraint_violations().body_dict['violations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.show_violation_df(baseline_statistics=baseline_statistics, \n",
    "                     latest_statistics=execution_statistics, \n",
    "                     violations=violations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "\n",
    "This section visualizes the distribution and renders the distribution statistics for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = mu.get_features(execution_statistics)\n",
    "feature_baselines = mu.get_features(baseline_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.show_distributions(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Stats vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.show_distributions(features, feature_baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
