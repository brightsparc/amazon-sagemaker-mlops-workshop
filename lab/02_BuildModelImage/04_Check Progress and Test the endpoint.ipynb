{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's monitor the training/deploying process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions():\n",
    "    actions = []\n",
    "    executionId = None\n",
    "    resp = codepipeline.get_pipeline_state( name=pipeline_name )\n",
    "    for stage in resp['stageStates']:\n",
    "        stageName = stage['stageName']\n",
    "        stageStatus = None\n",
    "        if stage.get('latestExecution') is not None:\n",
    "            stageStatus = stage['latestExecution']['status']\n",
    "            if executionId is None:\n",
    "                executionId = stage['latestExecution']['pipelineExecutionId']\n",
    "            elif stage['latestExecution']['pipelineExecutionId'] != executionId:\n",
    "                stageStatus = 'Old'\n",
    "        for action in stage['actionStates']:\n",
    "            actionName = action['actionName']\n",
    "            actionStatus = 'Old'\n",
    "            if action.get('latestExecution') is not None and stageStatus != 'Old':\n",
    "                actionStatus = action['latestExecution']['status']\n",
    "            actions.append( {'stageName': stageName, \n",
    "                             'stageStatus': stageStatus, \n",
    "                             'actionName': actionName, \n",
    "                             'actionStatus': actionStatus})\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_approval_token():\n",
    "    resp = codepipeline.get_pipeline_state( name=pipeline_name )\n",
    "    token = None\n",
    "    # Get the approve train status token\n",
    "    for stageState in resp['stageStates']:\n",
    "        if stageState['stageName'] == 'DeployApproval':\n",
    "            for actionState in stageState['actionStates']:\n",
    "                if actionState['actionName'] == 'ApproveDeploy':\n",
    "                    if actionState.get('latestExecution') is None:\n",
    "                        return None\n",
    "                    latestExecution = actionState['latestExecution']\n",
    "                    if latestExecution['status'] == 'InProgress':\n",
    "                        token = latestExecution['token']\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approval(token, result):\n",
    "    if token is None:\n",
    "        return\n",
    "    \n",
    "    codepipeline.put_approval_result(\n",
    "      pipelineName=pipeline_name,\n",
    "      stageName='DeployApproval',\n",
    "      actionName='ApproveDeploy',\n",
    "      result=result,\n",
    "      token=token\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approve(b):\n",
    "    result={\n",
    "        'summary': 'This is a great model! Put into production.',\n",
    "        'status': 'Approved'\n",
    "    }\n",
    "    approval(get_approval_token(), result) \n",
    "    button_box.close()\n",
    "    start_monitoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject(b):\n",
    "    result={\n",
    "        'summary': 'This is a rubbish model. Discard it',\n",
    "        'status': 'Rejected'\n",
    "    }\n",
    "    approval(get_approval_token(), result)\n",
    "    button_box.close()\n",
    "    start_monitoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_monitoring():\n",
    "    global button_box\n",
    "    \n",
    "    running = True\n",
    "    while running:\n",
    "        steps_ok = 0\n",
    "        for k,action in enumerate(get_actions()):\n",
    "            if action['actionStatus'] == 'Failed':\n",
    "                bar.bar_style='danger'\n",
    "                label.value='Ops! Something went wrong Stage[{}] Action[{}]'.format(\n",
    "                    action['stageName'], action['actionName'])\n",
    "                running = False\n",
    "                return\n",
    "\n",
    "            elif action['actionStatus'] == 'InProgress':\n",
    "                if get_approval_token() is not None:\n",
    "                    display(button_box)\n",
    "                    running = False\n",
    "                break\n",
    "            elif action['actionStatus'] == 'Old':\n",
    "                break\n",
    "            elif action['actionStatus'] == 'Succeeded':\n",
    "                steps_ok += 1\n",
    "        \n",
    "        label.value = \"Actions {}/{} - Current: Stage[{}] Action[{}]\".format( \n",
    "                k+1,max_actions, action['stageName'], action['actionName'] )\n",
    "        bar.value = steps_ok\n",
    "\n",
    "        if steps_ok == max_actions:\n",
    "            running = False\n",
    "        else:    \n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "codepipeline = boto3.client('codepipeline')\n",
    "pipeline_name = os.environ['PIPELINE_NAME']\n",
    "model_name = os.environ['MODEL_NAME']\n",
    "\n",
    "print('pipeline: {}'.format(pipeline_name))\n",
    "print('model name: {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approve_btn = widgets.Button(description=\"Approve\", button_style='success', icon='check')\n",
    "reject_btn = widgets.Button(description=\"Reject\", button_style='danger', icon='close')\n",
    "approve_btn.on_click(approve)\n",
    "reject_btn.on_click(reject)\n",
    "button_box = widgets.HBox([approve_btn, reject_btn])\n",
    "                \n",
    "max_actions = len(get_actions())\n",
    "label = widgets.Label(value=\"Loading...\")\n",
    "bar = widgets.IntProgress( value=0, min=0, max=max_actions, step=1, bar_style='info' )\n",
    "info_box = widgets.VBox([label, bar])\n",
    "\n",
    "display(info_box)\n",
    "start_monitoring()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, if everything went fine, we can test our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current execution id, and production endpoints\n",
    "response = codepipeline.get_pipeline_state( name=pipeline_name )\n",
    "executionId = response['stageStates'][-1]['latestExecution']['pipelineExecutionId']\n",
    "\n",
    "endpoint_name='mlops-{}-prd-{}'.format(model_name, executionId)\n",
    "processing_job_name='mlops-{}-pbl-{}'.format(model_name, executionId)\n",
    "schedule_name='mlops-{}-pms-{}'.format(model_name, executionId)\n",
    "\n",
    "# TODO: Get the Rest API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call tne endpoint with some content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "def test_endpoint(endpoint_name, payload, content_type='text/csv', custom_attributes=''):\n",
    "    resp = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=payload,\n",
    "        ContentType=content_type,\n",
    "        CustomAttributes=custom_attributes\n",
    "    )\n",
    "    return resp['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def read_csv_dataframe(path, engine='python'):\n",
    "    files = glob.glob(os.path.join(path, '*.csv'))\n",
    "    if len(files) > 0:\n",
    "        return pd.concat([pd.read_csv(fn, engine=engine) for fn in files], axis=0, ignore_index=True)\n",
    "\n",
    "# Load sample data\n",
    "df_test = read_csv_dataframe('input/data/validation').drop('class', axis=1)\n",
    "\n",
    "# Get predictions and join to sample data\n",
    "payload = df_test.to_csv(index=False).encode('utf-8')\n",
    "result = test_endpoint(endpoint_name, payload, 'text/csv', 'Headers').decode('utf-8')\n",
    "df_pred = pd.read_csv(StringIO(result))\n",
    "df_test.join(df_pred[['class_predictions','class_probability']]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load baseline\n",
    "\n",
    "Load baseline processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.model_monitor import BaseliningJob\n",
    "from sagemaker.model_monitor import MonitoringExecution\n",
    "from sagemaker.s3 import S3Downloader\n",
    "import pandas as pd\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "sm = boto3.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = BaseliningJob.from_processing_name(sagemaker_session, processing_job_name)\n",
    "status = baseline_job.describe()['ProcessingJobStatus']\n",
    "if status != 'Stopped':\n",
    "    raise(Exception('Processing job not complete, status: {}'.format(status)))\n",
    "    \n",
    "baseline_results_uri  = baseline_job.outputs[0].destination\n",
    "print('baseline results uri: {}'.format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the generated constraints and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df = pd.io.json.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_df = pd.io.json.json_normalize(baseline_job.suggested_constraints().body_dict[\"features\"])\n",
    "constraints_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "data_capture_prefix = '{}/datacapture'.format(model_name)\n",
    "print('data capture prefix: {}'.format(data_capture_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get capture files for this new endpoint\n",
    "result = s3.list_objects(Bucket=bucket, Prefix=data_capture_prefix)\n",
    "if not 'Contents' in result:\n",
    "    raise(Exception('No results vailable yet for location: {}'.format(results_prefix)))\n",
    "else:\n",
    "    capture_files = ['s3://{0}/{1}'.format(bucket, capture_file.get(\"Key\")) \n",
    "                     for capture_file in result.get('Contents')][::-1]\n",
    "    print(\"Captured Files: {}, top 3:\".format(len(capture_files)))\n",
    "    print(\"\\n \".join(capture_files[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p output/datacapture\n",
    "!aws s3 cp {capture_files[1]} output/datacapture/captured_data_example.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('output/datacapture/captured_data_example.jsonl', 'r') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    event = json.loads(lines[0])\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring Schedule\n",
    "\n",
    "The functions for plotting and rendering distribution statistics or constraint violations are implemented in a `utils` file so let's grab that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/awslabs/amazon-sagemaker-examples/master/sagemaker_model_monitor/visualization/utils.py\n",
    "import utils as mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the last succesful monitoring schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.list_monitoring_executions(MonitoringScheduleName=schedule_name)\n",
    "schedules = [m for m in response['MonitoringExecutionSummaries'] if m['MonitoringExecutionStatus'] == 'Stopped']\n",
    "if len(schedules) == 0:\n",
    "    raise(Exception('No completed schedules'))\n",
    "    \n",
    "schedule = schedules[0]\n",
    "    \n",
    "print('Schedule status: {}'.format(schedule['MonitoringExecutionStatus']))\n",
    "    \n",
    "processing_job_arn = schedule['ProcessingJobArn']\n",
    "execution = MonitoringExecution.from_processing_arn(sagemaker_session=sagemaker.Session(), processing_job_arn=processing_job_arn)\n",
    "exec_inputs = {inp['InputName']: inp for inp in execution.describe()['ProcessingInputs']}\n",
    "exec_results = execution.output.destination\n",
    "\n",
    "# List the files to confirm we have results\n",
    "!aws s3 ls $exec_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the underlying processing job\n",
    "from sagemaker.processing import ProcessingJob\n",
    "schedule_processing_job = ProcessingJob.from_processing_arn(sagemaker_session, processing_job_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The code below shows the violations and constraichecks across all features in a simple table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_statistics, violations = execution.statistics(), execution.constraint_violations()\n",
    "mu.show_violation_df(baseline_statistics=baseline_statistics, latest_statistics=execution_statistics, violations=violations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "\n",
    "This section visualizes the distribution and renders the distribution statistics for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = mu.get_features(execution_statistics)\n",
    "feature_baselines = mu.get_features(baseline_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.show_distributions(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Stats vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.show_distributions(features, feature_baselines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
