{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's monitor the training/deploying process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions():\n",
    "    actions = []\n",
    "    executionId = None\n",
    "    resp = codepipeline.get_pipeline_state( name=pipeline_name )\n",
    "    for stage in resp['stageStates']:\n",
    "        stageName = stage['stageName']\n",
    "        stageStatus = None\n",
    "        if stage.get('latestExecution') is not None:\n",
    "            stageStatus = stage['latestExecution']['status']\n",
    "            if executionId is None:\n",
    "                executionId = stage['latestExecution']['pipelineExecutionId']\n",
    "            elif stage['latestExecution']['pipelineExecutionId'] != executionId:\n",
    "                stageStatus = 'Old'\n",
    "        for action in stage['actionStates']:\n",
    "            actionName = action['actionName']\n",
    "            actionStatus = 'Old'\n",
    "            if action.get('latestExecution') is not None and stageStatus != 'Old':\n",
    "                actionStatus = action['latestExecution']['status']\n",
    "            actions.append( {'stageName': stageName, \n",
    "                             'stageStatus': stageStatus, \n",
    "                             'actionName': actionName, \n",
    "                             'actionStatus': actionStatus})\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_approval_token():\n",
    "    resp = codepipeline.get_pipeline_state( name=pipeline_name )\n",
    "    token = None\n",
    "    # Get the approve train status token\n",
    "    for stageState in resp['stageStates']:\n",
    "        if stageState['stageName'] == 'DeployDev':\n",
    "            for actionState in stageState['actionStates']:\n",
    "                if actionState['actionName'] == 'ApproveDeploy':\n",
    "                    if actionState.get('latestExecution') is None:\n",
    "                        return None\n",
    "                    latestExecution = actionState['latestExecution']\n",
    "                    if latestExecution['status'] == 'InProgress':\n",
    "                        token = latestExecution['token']\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approval(token, result):\n",
    "    if token is None:\n",
    "        return\n",
    "    \n",
    "    codepipeline.put_approval_result(\n",
    "      pipelineName=pipeline_name,\n",
    "      stageName='DeployDev',\n",
    "      actionName='ApproveDeploy',\n",
    "      result=result,\n",
    "      token=token\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approve(b):\n",
    "    result={\n",
    "        'summary': 'This is a great model! Put into production.',\n",
    "        'status': 'Approved'\n",
    "    }\n",
    "    approval(get_approval_token(), result) \n",
    "    button_box.close()\n",
    "    start_monitoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject(b):\n",
    "    result={\n",
    "        'summary': 'This is a rubbish model. Discard it',\n",
    "        'status': 'Rejected'\n",
    "    }\n",
    "    approval(get_approval_token(), result)\n",
    "    button_box.close()\n",
    "    start_monitoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_monitoring():\n",
    "    global button_box\n",
    "    \n",
    "    running = True\n",
    "    while running:\n",
    "        steps_ok = 0\n",
    "        for k,action in enumerate(get_actions()):\n",
    "            if action['actionStatus'] == 'Failed':\n",
    "                bar.bar_style='danger'\n",
    "                label.value='Ops! Something went wrong Stage[{}] Action[{}]'.format(\n",
    "                    action['stageName'], action['actionName'])\n",
    "                running = False\n",
    "                return\n",
    "\n",
    "            elif action['actionStatus'] == 'InProgress':\n",
    "                if get_approval_token() is not None:\n",
    "                    display(button_box)\n",
    "                    running = False\n",
    "                break\n",
    "            elif action['actionStatus'] == 'Old':\n",
    "                break\n",
    "            elif action['actionStatus'] == 'Succeeded':\n",
    "                steps_ok += 1\n",
    "        \n",
    "        label.value = \"Actions {}/{} - Current: Stage[{}] Action[{}]\".format( \n",
    "                k+1,max_actions, action['stageName'], action['actionName'] )\n",
    "        bar.value = steps_ok\n",
    "\n",
    "        if steps_ok == max_actions:\n",
    "            running = False\n",
    "        else:    \n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "codepipeline = boto3.client('codepipeline')\n",
    "pipeline_name = os.environ['PIPELINE_NAME']\n",
    "model_name = os.environ['MODEL_NAME']\n",
    "\n",
    "print('pipeline: {}'.format(pipeline_name))\n",
    "print('model name: {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approve_btn = widgets.Button(description=\"Approve\", button_style='success', icon='check')\n",
    "reject_btn = widgets.Button(description=\"Reject\", button_style='danger', icon='close')\n",
    "approve_btn.on_click(approve)\n",
    "reject_btn.on_click(reject)\n",
    "button_box = widgets.HBox([approve_btn, reject_btn])\n",
    "                \n",
    "max_actions = len(get_actions())\n",
    "label = widgets.Label(value=\"Loading...\")\n",
    "bar = widgets.IntProgress( value=0, min=0, max=max_actions, step=1, bar_style='info' )\n",
    "info_box = widgets.VBox([label, bar])\n",
    "\n",
    "display(info_box)\n",
    "start_monitoring()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, if everything went fine, we can test our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current execution id, and production endpoints\n",
    "response = codepipeline.get_pipeline_state( name=pipeline_name )\n",
    "executionId = response['stageStates'][-1]['latestExecution']['pipelineExecutionId']\n",
    "\n",
    "endpoint_name='mlops-{}-prd-{}'.format(model_name, executionId)\n",
    "processing_job_name='mlops-{}-pbl-{}'.format(model_name, executionId)\n",
    "schedule_name='mlops-{}-pms-{}'.format(model_name, executionId)\n",
    "\n",
    "print('execution id: {}'.format(executionId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#executionId = '46d4a3c0-517c-4e77-a2b7-3f84cb6e4738'\n",
    "endpoint_name='mlops-{}-prd-{}'.format(model_name, executionId)\n",
    "processing_job_name='mlops-{}-pbl-{}'.format(model_name, executionId)\n",
    "schedule_name='mlops-{}-pms-{}'.format(model_name, executionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the endpoint with some expected, and unexpected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "def test_endpoint(endpoint_name, payload, content_type='text/csv', custom_attributes=''):\n",
    "    resp = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=payload,\n",
    "        ContentType=content_type,\n",
    "        CustomAttributes=custom_attributes\n",
    "    )\n",
    "    return resp['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that we can send some traffic to the end point\n",
    "test_endpoint(endpoint_name, 'text\\nthis is a test'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "monitor_sample = [\n",
    "# Define some typical data\n",
    "    'cool asian food pty melbourne au', # eathing out\n",
    "    'woolworths 3188 brunswick au', # groceries\n",
    "    'airbnb * blaa surry hills au', # travel\n",
    "    'lido cinemas hawthorn au', # entertainment\n",
    "    'northcote indoor spo thornbury au', # health\n",
    "# Define some data which is out of bounds of usual sample\n",
    "    'one',\n",
    "    '1',\n",
    "    'fdkslfjkdlsjfkdsfkldjsklfmdskfjkdlsjfkldsjfkldsjfkldsjklfjsdkjfklds',\n",
    "    'this is a very long sentance that should skew the character and word count',\n",
    "]\n",
    "\n",
    "# Send off a series of invidual requests for each sample\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(1000)):\n",
    "    for sample in monitor_sample:\n",
    "        payload = 'text\\n{}'.format(sample).encode('utf-8')\n",
    "        test_endpoint(endpoint_name, payload).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load baseline\n",
    "\n",
    "Load baseline processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.model_monitor import BaseliningJob\n",
    "from sagemaker.model_monitor import MonitoringExecution\n",
    "from sagemaker.s3 import S3Downloader\n",
    "import pandas as pd\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "sm = boto3.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = BaseliningJob.from_processing_name(sagemaker_session, processing_job_name)\n",
    "status = baseline_job.describe()['ProcessingJobStatus']\n",
    "if status != 'Stopped':\n",
    "    raise(Exception('Processing job not complete, status: {}'.format(status)))\n",
    "    \n",
    "baseline_results_uri  = baseline_job.outputs[0].destination\n",
    "print('baseline results uri: {}'.format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the generated constraints and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_statistics = baseline_job.baseline_statistics()\n",
    "schema_df = pd.io.json.json_normalize(baseline_statistics.body_dict[\"features\"])\n",
    "schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_df = pd.io.json.json_normalize(baseline_job.suggested_constraints().body_dict[\"features\"])\n",
    "constraints_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "data_capture_prefix = '{}/datacapture/{}/AllTraffic/'.format(model_name, endpoint_name)\n",
    "print('data capture prefix: {}'.format(data_capture_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get capture files for this new endpoint\n",
    "result = s3.list_objects(Bucket=bucket, Prefix=data_capture_prefix)\n",
    "if not 'Contents' in result:\n",
    "    raise(Exception('No results vailable yet for location: {}'.format(results_prefix)))\n",
    "else:\n",
    "    capture_files = ['s3://{0}/{1}'.format(bucket, capture_file.get(\"Key\")) \n",
    "                     for capture_file in result.get('Contents')][::-1]\n",
    "    print(\"Captured Files: {}, top 3:\".format(len(capture_files)))\n",
    "    print(\"\\n \".join(capture_files[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p output/datacapture\n",
    "!aws s3 cp {capture_files[1]} output/datacapture/captured_data_example.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('output/datacapture/captured_data_example.jsonl', 'r') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    event = json.loads(lines[0])\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Monitoring Schedule\n",
    "\n",
    "The functions for plotting and rendering distribution statistics or constraint violations are implemented in a `utils` file so let's grab that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/awslabs/amazon-sagemaker-examples/master/sagemaker_model_monitor/visualization/utils.py\n",
    "import utils as mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the last succesful monitoring schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.list_monitoring_executions(MonitoringScheduleName=schedule_name)\n",
    "schedules = [m for m in response['MonitoringExecutionSummaries'] if m['MonitoringExecutionStatus'] == 'Stopped']\n",
    "if len(schedules) == 0:\n",
    "    raise(Exception('No completed schedules'))\n",
    "    \n",
    "schedule = schedules[0]\n",
    "processing_job_arn = schedule['ProcessingJobArn']\n",
    "print('Schedule status: {}\\n{}'.format(schedule['MonitoringExecutionStatus'], processing_job_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List results from the underlying processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_results = schedule_processing_job.outputs[0].destination\n",
    "print(exec_results)\n",
    "\n",
    "!aws s3 ls $exec_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the current status of processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingJob\n",
    "schedule_processing_job = ProcessingJob.from_processing_arn(sagemaker_session, processing_job_arn)\n",
    "schedule_processing_job.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Schedule immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from urllib.parse import urlparse\n",
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "def get_model_monitor_container_uri(region):\n",
    "    container_uri_format = '{0}.dkr.ecr.{1}.amazonaws.com/sagemaker-model-monitor-analyzer'\n",
    "    \n",
    "    regions_to_accounts = {\n",
    "        'eu-north-1': '895015795356',\n",
    "        'me-south-1': '607024016150',\n",
    "        'ap-south-1': '126357580389',\n",
    "        'us-east-2': '680080141114',\n",
    "        'us-east-2': '777275614652',\n",
    "        'eu-west-1': '468650794304',\n",
    "        'eu-central-1': '048819808253',\n",
    "        'sa-east-1': '539772159869',\n",
    "        'ap-east-1': '001633400207',\n",
    "        'us-east-1': '156813124566',\n",
    "        'ap-northeast-2': '709848358524',\n",
    "        'eu-west-2': '749857270468',\n",
    "        'ap-northeast-1': '574779866223',\n",
    "        'us-west-2': '159807026194',\n",
    "        'us-west-1': '890145073186',\n",
    "        'ap-southeast-1': '245545462676',\n",
    "        'ap-southeast-2': '563025443158',\n",
    "        'ca-central-1': '536280801234'\n",
    "    }\n",
    "    \n",
    "    container_uri = container_uri_format.format(regions_to_accounts[region], region)\n",
    "    return container_uri\n",
    "\n",
    "def get_file_name(url):\n",
    "    a = urlparse(url)\n",
    "    return os.path.basename(a.path)\n",
    "\n",
    "def run_model_monitor_job_processor(region, instance_type, role, data_capture_path, statistics_path, constraints_path, reports_path,\n",
    "                                    instance_count=1, preprocessor_path=None, postprocessor_path=None, publish_cloudwatch_metrics='Disabled'):\n",
    "    \n",
    "    data_capture_sub_path = data_capture_path[data_capture_path.rfind('datacapture/') :]\n",
    "    data_capture_sub_path = data_capture_sub_path[data_capture_sub_path.find('/') + 1 :]\n",
    "    processing_output_paths = reports_path + '/' + data_capture_sub_path\n",
    "    \n",
    "    input_1 = ProcessingInput(input_name='input_1',\n",
    "                          source=data_capture_path,\n",
    "                          destination='/opt/ml/processing/input/endpoint/' + data_capture_sub_path,\n",
    "                          s3_data_type='S3Prefix',\n",
    "                          s3_input_mode='File')\n",
    "\n",
    "    baseline = ProcessingInput(input_name='baseline',\n",
    "                               source=statistics_path,\n",
    "                               destination='/opt/ml/processing/baseline/stats',\n",
    "                               s3_data_type='S3Prefix',\n",
    "                               s3_input_mode='File')\n",
    "\n",
    "    constraints = ProcessingInput(input_name='constraints',\n",
    "                                  source=constraints_path,\n",
    "                                  destination='/opt/ml/processing/baseline/constraints',\n",
    "                                  s3_data_type='S3Prefix',\n",
    "                                  s3_input_mode='File')\n",
    "\n",
    "    outputs = ProcessingOutput(output_name='result',\n",
    "                               source='/opt/ml/processing/output',\n",
    "                               destination=processing_output_paths,\n",
    "                               s3_upload_mode='Continuous')\n",
    "\n",
    "    env = {'baseline_constraints': '/opt/ml/processing/baseline/constraints/' + get_file_name(constraints_path),\n",
    "           'baseline_statistics': '/opt/ml/processing/baseline/stats/' + get_file_name(statistics_path),\n",
    "           'dataset_format': '{\"sagemakerCaptureJson\":{\"captureIndexNames\":[\"endpointInput\",\"endpointOutput\"]}}',\n",
    "           'dataset_source': '/opt/ml/processing/input/endpoint',\n",
    "           'output_path': '/opt/ml/processing/output',\n",
    "           'publish_cloudwatch_metrics': publish_cloudwatch_metrics }\n",
    "    \n",
    "    inputs=[input_1, baseline, constraints]\n",
    "    \n",
    "    if postprocessor_path:\n",
    "        env['post_analytics_processor_script'] = '/opt/ml/processing/code/postprocessing/' + get_file_name(postprocessor_path)\n",
    "        \n",
    "        post_processor_script = ProcessingInput(input_name='post_processor_script',\n",
    "                                                source=postprocessor_path,\n",
    "                                                destination='/opt/ml/processing/code/postprocessing',\n",
    "                                                s3_data_type='S3Prefix',\n",
    "                                                s3_input_mode='File')\n",
    "        inputs.append(post_processor_script)\n",
    "\n",
    "    if preprocessor_path:\n",
    "        env['record_preprocessor_script'] = '/opt/ml/processing/code/preprocessing/' + get_file_name(preprocessor_path)\n",
    "         \n",
    "        pre_processor_script = ProcessingInput(input_name='pre_processor_script',\n",
    "                                               source=preprocessor_path,\n",
    "                                               destination='/opt/ml/processing/code/preprocessing',\n",
    "                                               s3_data_type='S3Prefix',\n",
    "                                               s3_input_mode='File')\n",
    "        \n",
    "        inputs.append(pre_processor_script) \n",
    "    \n",
    "    processor = Processor(image_uri = get_model_monitor_container_uri(region),\n",
    "                          instance_count = instance_count,\n",
    "                          instance_type = instance_type,\n",
    "                          role=role,\n",
    "                          env = env)\n",
    "    \n",
    "    processor.run(inputs=inputs, outputs=[outputs])\n",
    "    return processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the last statistics/contstraints from capture files\n",
    "s3_data_capture_path = capture_files[len(capture_files) - 1][: capture_files[len(capture_files) - 1].rfind('/')]\n",
    "s3_statistics_path = baseline_results_uri + '/statistics.json'\n",
    "s3_constraints_path = baseline_results_uri + '/constraints.json'\n",
    "\n",
    "print(s3_data_capture_path)\n",
    "print(s3_statistics_path)\n",
    "print(s3_constraints_path)\n",
    "\n",
    "s3_reports_path = 's3://{0}/{1}/monitoring/reports'.format(bucket, model_name)\n",
    "print(s3_reports_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "processor = run_model_monitor_job_processor(region, 'ml.m5.xlarge', role, \n",
    "                                s3_data_capture_path, s3_statistics_path, s3_constraints_path, s3_reports_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the processing job arn from logs, or output\n",
    "processing_job_arn = processor.describe()['ProcessingJobArn']\n",
    "processing_job_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring results\n",
    "\n",
    "The code below shows the violations and constraichecks across all features in a simple table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = MonitoringExecution.from_processing_arn(sagemaker_session=sagemaker.Session(), processing_job_arn=processing_job_arn)\n",
    "exec_inputs = {inp['InputName']: inp for inp in execution.describe()['ProcessingInputs']}\n",
    "exec_results = execution.output.destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $exec_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the baseline results\n",
    "baseline_statistics_filepath = exec_inputs['baseline']['S3Input']['S3Uri'] if 'baseline' in exec_inputs else None\n",
    "execution_statistics_filepath = os.path.join(exec_results, 'statistics.json')\n",
    "violations_filepath = os.path.join(exec_results, 'constraint_violations.json')\n",
    "\n",
    "baseline_statistics = json.loads(S3Downloader.read_file(baseline_statistics_filepath)) if baseline_statistics_filepath is not None else None\n",
    "execution_statistics = json.loads(S3Downloader.read_file(execution_statistics_filepath))\n",
    "violations = json.loads(S3Downloader.read_file(violations_filepath))['violations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.show_violation_df(baseline_statistics=baseline_statistics, latest_statistics=execution_statistics, violations=violations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "\n",
    "This section visualizes the distribution and renders the distribution statistics for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = mu.get_features(execution_statistics)\n",
    "feature_baselines = mu.get_features(baseline_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.show_distributions(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Stats vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.show_distributions(features, feature_baselines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
